{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tiania _Model Fashion MNIST Database.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tianiachan/Data640DeepLearning/blob/main/Tiania__Model_Fashion_MNIST_Database.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmL2Ux_gOlt2"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tarfile\n",
        "import tensorflow.keras \n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCbUDKiaPJNK"
      },
      "source": [
        "<p>Now lets load up the data.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjFtMaMoPPEK",
        "outputId": "45ef6d1e-a17f-4721-ac17-faf013bc1c6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "(train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()\n",
        "train_y = tensorflow.keras.utils.to_categorical(train_y, 10)\n",
        "test_y = tensorflow.keras.utils.to_categorical(test_y, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_g8UaTiPXUs",
        "outputId": "dde01a24-97e4-4cee-b5fd-36acb15251d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "train_x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI7EkNJlP77k"
      },
      "source": [
        "<p>Now that we've imported the data, we'll need to start importing what we need from Keras to build our network. Below is a basic network. Note that the images are greyscale, so there is no color channel like there is in some of the other datasets.</p>\n",
        "\n",
        "<p>Also, since there's no color channel, we'll use \"1D\" layers not \"2D\" layers as are used when we have channels for colors.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt2qR-eXPcE0"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, BatchNormalization, Flatten, Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfExr5Z7Pdmv"
      },
      "source": [
        "<p>Now it's time for us to start building the network. Build below is a sample network you can play with as a starting point for your assignment. Feel free to expand on this, or start your own from scratch!</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5QXWQjlQxiT"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(filters = 236, kernel_size = 2,  input_shape = (28, 28)))\n",
        "model.add(MaxPooling1D(pool_size = 2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv1D(filters = 128, kernel_size = 2))\n",
        "model.add(MaxPooling1D(pool_size = 2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units = 10, activation = 'softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-v7wv-CPhu9"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', \n",
        "              optimizer = tensorflow.keras.optimizers.Adadelta(), \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR4-mhC2Rq9N",
        "outputId": "ebaf18c7-914c-4960-b70e-28e99137932a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "model.fit(train_x, train_y, epochs = 10, batch_size = 128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 2.7640 - accuracy: 0.1699\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 2.2365 - accuracy: 0.2787\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 1.8726 - accuracy: 0.3790\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 1.6294 - accuracy: 0.4444\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 19s 42ms/step - loss: 1.4609 - accuracy: 0.4948\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 1.3358 - accuracy: 0.5355\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 1.2441 - accuracy: 0.5690\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 1.1709 - accuracy: 0.5932\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 1.1148 - accuracy: 0.6127\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 1.0694 - accuracy: 0.6301\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff453d4b668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TIDeyw0PgWc"
      },
      "source": [
        "<p>Now that we've trained the network, lets see how well it works on some unseen data!</p> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1H5a0DQReUd",
        "outputId": "d718521b-0368-4af3-c649-4d41fba982d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "score = model.evaluate(test_x, test_y)\n",
        "print('\\nloss is: ' + str(score[0]))\n",
        "print('accuracy is: ' + str(score[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8870 - accuracy: 0.7005\n",
            "\n",
            "loss is: 0.886969804763794\n",
            "accuracy is: 0.7005000114440918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnWEYUaFbwzE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}