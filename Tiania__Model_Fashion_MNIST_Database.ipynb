{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tiania _Model Fashion MNIST Database.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tianiachan/Data640DeepLearning/blob/main/Tiania__Model_Fashion_MNIST_Database.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmL2Ux_gOlt2"
      },
      "source": [
        "#import libraries for ML models\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tarfile\n",
        "import tensorflow.keras \n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCbUDKiaPJNK"
      },
      "source": [
        "<p>Now lets load up the data.</p>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function to visualize the image in the file\n",
        "def show(image):\n",
        "    \"\"\"\n",
        "    Render a given numpy.uint8 2D array of pixel data.\n",
        "    \"\"\"\n",
        "    from matplotlib import pyplot\n",
        "    import matplotlib as mpl\n",
        "    fig = pyplot.figure()\n",
        "    ax = fig.add_subplot(1,1,1)\n",
        "    imgplot = ax.imshow(image, cmap=mpl.cm.Greys)\n",
        "    imgplot.set_interpolation('nearest')\n",
        "    ax.xaxis.set_ticks_position('top')\n",
        "    ax.yaxis.set_ticks_position('left')\n",
        "    pyplot.show()"
      ],
      "metadata": {
        "id": "Bkxa__Y_6xtT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjFtMaMoPPEK"
      },
      "source": [
        "#import the data in from fashion mnist\n",
        "(train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()\n",
        "train_y = tensorflow.keras.utils.to_categorical(train_y, 10)\n",
        "test_y = tensorflow.keras.utils.to_categorical(test_y, 10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show first image in training data\n",
        "show(train_x[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "zdYcNA2w9Sv4",
        "outputId": "207cd60b-0e8f-467f-ea48-44d679423735"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_g8UaTiPXUs",
        "outputId": "8d5411a8-4084-4f2b-db97-70d2eb535b04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#get the shape of the image which is 60000 instances of 28x28 pixel sized images\n",
        "train_x.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI7EkNJlP77k"
      },
      "source": [
        "<p>Now that we've imported the data, we'll need to start importing what we need from Keras to build our network. Below is a basic network. Note that the images are greyscale, so there is no color channel like there is in some of the other datasets.</p>\n",
        "\n",
        "<p>Also, since there's no color channel, we'll use \"1D\" layers not \"2D\" layers as are used when we have channels for colors.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt2qR-eXPcE0"
      },
      "source": [
        "#additional libraries to add to top after understanding this model better\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, BatchNormalization, Flatten, Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfExr5Z7Pdmv"
      },
      "source": [
        "<p>Now it's time for us to start building the network. Build below is a sample network you can play with as a starting point for your assignment. Feel free to expand on this, or start your own from scratch!</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5QXWQjlQxiT"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(filters = 236, kernel_size = 2,  input_shape = (28, 28)))\n",
        "model.add(MaxPooling1D(pool_size = 2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv1D(filters = 128, kernel_size = 2))\n",
        "model.add(MaxPooling1D(pool_size = 2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units = 10, activation = 'softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-v7wv-CPhu9"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', \n",
        "              optimizer = tensorflow.keras.optimizers.Adadelta(), \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR4-mhC2Rq9N",
        "outputId": "ebaf18c7-914c-4960-b70e-28e99137932a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "model.fit(train_x, train_y, epochs = 10, batch_size = 128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 2.7640 - accuracy: 0.1699\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 2.2365 - accuracy: 0.2787\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 1.8726 - accuracy: 0.3790\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 1.6294 - accuracy: 0.4444\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 19s 42ms/step - loss: 1.4609 - accuracy: 0.4948\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 1.3358 - accuracy: 0.5355\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 1.2441 - accuracy: 0.5690\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 1.1709 - accuracy: 0.5932\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 1.1148 - accuracy: 0.6127\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 1.0694 - accuracy: 0.6301\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff453d4b668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TIDeyw0PgWc"
      },
      "source": [
        "<p>Now that we've trained the network, lets see how well it works on some unseen data!</p> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1H5a0DQReUd",
        "outputId": "d718521b-0368-4af3-c649-4d41fba982d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "score = model.evaluate(test_x, test_y)\n",
        "print('\\nloss is: ' + str(score[0]))\n",
        "print('accuracy is: ' + str(score[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8870 - accuracy: 0.7005\n",
            "\n",
            "loss is: 0.886969804763794\n",
            "accuracy is: 0.7005000114440918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnWEYUaFbwzE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}