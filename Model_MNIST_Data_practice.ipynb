{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Model MNIST Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tianiachan/Data640DeepLearning/blob/main/Model_MNIST_Data_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eikk_y-rRVZx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV-6gday0O6q"
      },
      "source": [
        "<h1>Model the MNIST Handwriting Data in Python</h1>\n",
        "<p>This script imports the MNIST handwriting recognition data and models it in Python</p>\n",
        "<p>The first step is to import our standard libraries for math, data science and working with the file system.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijzEuyx40O6s"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import struct\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qwaLyvQ0O6u"
      },
      "source": [
        "<p>Next we need to import the items we're going to use to build our Neural Network. We'll be using Keras, which is a nice framework that builds based on human-readable intuition, rather than very complex math. We'll need to import the whole library, but we'll also add a model (Sequential) and some layer types so we can use them later.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tuo9s2R50O6v"
      },
      "source": [
        "# Import Keras, which gives us a nice human readable way of \n",
        "#    building our model. \n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XMK7lQj0O66"
      },
      "source": [
        "<p>This function creates an image out of the pixel level data in the data set. In a minute, we'll use it to examine the first image from the file.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wJaBTrC0O67"
      },
      "source": [
        "def show(image):\n",
        "    \"\"\"\n",
        "    Render a given numpy.uint8 2D array of pixel data.\n",
        "    \"\"\"\n",
        "    from matplotlib import pyplot\n",
        "    import matplotlib as mpl\n",
        "    fig = pyplot.figure()\n",
        "    ax = fig.add_subplot(1,1,1)\n",
        "    imgplot = ax.imshow(image, cmap=mpl.cm.Greys)\n",
        "    imgplot.set_interpolation('nearest')\n",
        "    ax.xaxis.set_ticks_position('top')\n",
        "    ax.yaxis.set_ticks_position('left')\n",
        "    pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBHP05Jl0O69"
      },
      "source": [
        "<p>Now lets import both the training and the test data.</p>\n",
        "<p>Once we've done that, we'll have a two lists of tules containing the training data and labels in one set, and the test data and labels in the other set.</p>\n",
        "<p>Both the training and test data comes in two parts - the first is labeled x and holds all the data we'll use for our predictions. The second is labeled y and contains the target values. We can get all four of those matricies directly from the load data function.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9reryMNJ0O6-",
        "outputId": "91df306e-bd34-4af9-a70c-388c4040e3c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#Read in the training and test data.\n",
        "(train_x, train_y), (test_x, test_y) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcGoZe7L0O7B"
      },
      "source": [
        "<p>In this cell, we print the first image from the dataset (a five) by calling the \"show\" function we defined above. This prints the image to the console, and we can see it looks like a handwritten 5.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Gdkre6h0O7C",
        "outputId": "44278ee8-5499-444e-e608-35faeb424dbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# Show the image using the function above. \n",
        "show(train_x[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iRLu1ys0O7G"
      },
      "source": [
        "<p>Now lets see what the computer sees. In the function below, we print the raw pixel values of each cell. Remember, the darker the cell, the higher the pixel value, so high numbers are dark pixels, low numbers are lighter pixels and 0s are white pixels.</p><p>Note that you can still sort of see the 5 in the matrix below by looking at where the numbers are bigger. That gives us some hope we can get the computer to see it, right?</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "lAzupe670O7I",
        "outputId": "005803b7-5440-4fbc-a561-b3df27922ea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Make the console wide enough to read all the pixels. \n",
        "np.core.arrayprint._line_width = 300\n",
        "# Print the matrix of values in the first image\n",
        "print(train_x[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0T8s9E00O7K"
      },
      "source": [
        "<p>To make the data work with the deep learning network we're going to build, we need to split it into data (i.e. the pixel matrix) and labels. We'll call the data 'x' and the labels 'y.'</p>\n",
        "<p>In the function below, train_x and test_x are created by iterating through the training and testing data and taking the data portion of each pair. Now we have an array of training data and testing data, with each item in the array representing a matrix of pixel values for a single image (think something that looks like a list containing items that look like the matrix we printed in the last step).</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i_Hnr3K0O7P"
      },
      "source": [
        "# Now convert from a single label into a 1x10 array of class numbers \n",
        "#   so 1 for the class representing the image, and 0 for everything else\n",
        "#   These are just like dummy variables. \n",
        "train_y = tensorflow.keras.utils.to_categorical(train_y, 10)\n",
        "test_y = tensorflow.keras.utils.to_categorical(test_y, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "0WxDoVRr0O7R",
        "outputId": "a29eb535-c896-44ef-f940-691a6a51e1b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "train_x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll-9Iu320O7U"
      },
      "source": [
        "<h2>Creating the Model</h2>\n",
        "<p>Oh my goodness, we're finally ready to create the model... That took a long time, right? Fortunately, by the time we start creating the model, we're pretty much done. </p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_vc_jJN0O7V"
      },
      "source": [
        "<p>For this example, we're going to create a simple sequential model, where every node in each layer is connected to every node in the following layer.</p>\n",
        "<p>The first thing to do is to create the model, and tell Keras the type of model we'd like.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0TCjqgq0O7V"
      },
      "source": [
        "# Create a simple sequiential model. \n",
        "model = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28vzmD2h0O7X"
      },
      "source": [
        "<p>Now we add our first layer. It's a 'dense' layer, which is basically just a normal layer, similar to those we've created in other simpler neural networks.</p>\n",
        "<p>We have to define several things - the first thing we define is how many units we want in this hidden layer. Since we have a lot of values, because we have a lot of pixels, we can use a much higher number of units in the hidden layer than we can for smaller datasets. In thsi case, we use 156 units in the first hidden layer</p>\n",
        "<p>The second thing we define is the input shape. Out input shape is the shape of our image, which is 2D. That means the layer is expecting a 28x28 matrix as an input. We could have flattened our dataset and create a single row of 784 (28x28) pixels and given the matrix a flat input, but we didn't.</p>\n",
        "<p>Having set up the structure of the input, we then have to set up the activation function. The activation function defines how the node will translate the input into an output. A ReLU function (Rectified Linear Unit) is flat when x is less than 0 and linear when x is greater than 0. It's a very popular activation function for deep learning neural networks.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke2rzZrW0O7Y"
      },
      "source": [
        "model.add(Dense(units = 156, input_shape = (28, 28)))\n",
        "model.add(Activation('relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vnclOPY0O7b"
      },
      "source": [
        "<p>Next we'll add a second layer to the netural network. We add another dense layer, with 156 units again, and using the same activation function. Note that in this layer, we don't need to re-define the input shape, because Keras will carry the output from from the previous layer through as the input into this layer.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbmXailB0O7b"
      },
      "source": [
        "model.add(Dense(units = 156, activation = 'relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dz3rf3Kn0O7g"
      },
      "source": [
        "<p>Now - up until now, we've been working with a matrix of values because our input was a 2D matrix. To predict a 1D array of probabilities for each of the 10 digits, we need to flatten our 2D matrix to 1D. To do that, we add a 'flattening' layer to our network.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcpxSsGB0O7i"
      },
      "source": [
        "model.add(Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WudRM8D90O7l"
      },
      "source": [
        "<p>Now we're adding our final layer - this layer is the output layer, and there are two things for us to take into consideration. First, we have to have the same number of units in our final layer as we have in our output. In this case, we're predicting the probability the image is of a digit 0-9, so we need 10 output units, and each unit will hold the probability for one of the 10 output classes.</p>\n",
        "<p>We also need to define a new function, because we're predicting classifications, so we don't want a linear output function. The softmax function is similar to the function used in logisitc regression, so our final outputs will be bounded between 0 and 1.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MJ58LFx0O7l"
      },
      "source": [
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkl-9UwC0O7p"
      },
      "source": [
        "<p>Now we have to 'compile' the model. When we compile the model, we define the loss function, the optimization algorithm and the metric we'll use to determine how 'successful' the model was. These will be used on the training and validation sets, and during back-propogation to determine how the weights are adjusted.</p>\n",
        "<p>These values have an impact on both the final network and how accurate it is and how long it takes for the network to train.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xyQ1Gcs0O7r"
      },
      "source": [
        "# Comile the model and set the loss functions, and targets, etc. \n",
        "model.compile(loss = 'categorical_crossentropy', \n",
        "              optimizer = tensorflow.keras.optimizers.Adadelta(), \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD5I0UKp0O7v"
      },
      "source": [
        "<p>Now we can train the model. Once again, we have some options. Aren't options fun?!</p>\n",
        "<p>First we define the training data, and the trianing labels - thats train_x and train_y. Then we define the number of 'epochs.' An epoch is a single pass through all the training data. Since we have 60,000 training examples, each epoch will be a pass through all 60,000 training examples. The greater the number of epochs, the more passes through the data. The more passes through the data, the longer the model will take to train, but (potentially) the more accurate the final model will be.</p>\n",
        "<p>We also select the \"batch size,\" which is the number of training examples presented before new weights are calculated. Generally speaking, a higher batch size will result in faster training (because we take larger chunks from the training data), but the network will converge more slowly (because we don't calculate new weights as often). How you set them depends on how long the training is taking and how you see the accuracy and loss change during each trianing epoch.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "S4AAhjeu0O7w",
        "outputId": "18d066fb-85e8-4975-f677-fa7d2b5d2d5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train_x, train_y, epochs = 50, batch_size = 128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 35.6455 - accuracy: 0.1297\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 20.9582 - accuracy: 0.2180\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 14.7954 - accuracy: 0.3424\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 11.3021 - accuracy: 0.4453\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 9.1463 - accuracy: 0.5219\n",
            "Epoch 6/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 7.7355 - accuracy: 0.5767\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 6.7343 - accuracy: 0.6183\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 5.9829 - accuracy: 0.6515\n",
            "Epoch 9/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 5.4015 - accuracy: 0.6783\n",
            "Epoch 10/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 4.9408 - accuracy: 0.6993\n",
            "Epoch 11/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 4.5680 - accuracy: 0.7169\n",
            "Epoch 12/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 4.2613 - accuracy: 0.7325\n",
            "Epoch 13/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 4.0022 - accuracy: 0.7446\n",
            "Epoch 14/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 3.7782 - accuracy: 0.7550\n",
            "Epoch 15/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 3.5824 - accuracy: 0.7647\n",
            "Epoch 16/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 3.4119 - accuracy: 0.7728\n",
            "Epoch 17/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 3.2613 - accuracy: 0.7807\n",
            "Epoch 18/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 3.1276 - accuracy: 0.7879\n",
            "Epoch 19/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 3.0067 - accuracy: 0.7939\n",
            "Epoch 20/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.8978 - accuracy: 0.7997\n",
            "Epoch 21/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.7971 - accuracy: 0.8040\n",
            "Epoch 22/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.7047 - accuracy: 0.8084\n",
            "Epoch 23/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.6192 - accuracy: 0.8128\n",
            "Epoch 24/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.5420 - accuracy: 0.8169\n",
            "Epoch 25/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.4696 - accuracy: 0.8210\n",
            "Epoch 26/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.4013 - accuracy: 0.8247\n",
            "Epoch 27/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.3399 - accuracy: 0.8282\n",
            "Epoch 28/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.2815 - accuracy: 0.8310\n",
            "Epoch 29/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.2277 - accuracy: 0.8341\n",
            "Epoch 30/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.1771 - accuracy: 0.8369\n",
            "Epoch 31/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.1285 - accuracy: 0.8393\n",
            "Epoch 32/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.0825 - accuracy: 0.8415\n",
            "Epoch 33/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.0391 - accuracy: 0.8440\n",
            "Epoch 34/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.9982 - accuracy: 0.8459\n",
            "Epoch 35/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.9589 - accuracy: 0.8483\n",
            "Epoch 36/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.9220 - accuracy: 0.8498\n",
            "Epoch 37/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.8867 - accuracy: 0.8520\n",
            "Epoch 38/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.8527 - accuracy: 0.8537\n",
            "Epoch 39/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.8208 - accuracy: 0.8552\n",
            "Epoch 40/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.7899 - accuracy: 0.8570\n",
            "Epoch 41/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.7598 - accuracy: 0.8583\n",
            "Epoch 42/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.7313 - accuracy: 0.8599\n",
            "Epoch 43/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.7041 - accuracy: 0.8610\n",
            "Epoch 44/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.6778 - accuracy: 0.8626\n",
            "Epoch 45/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.6523 - accuracy: 0.8633\n",
            "Epoch 46/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.6277 - accuracy: 0.8647\n",
            "Epoch 47/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.6041 - accuracy: 0.8662\n",
            "Epoch 48/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.5812 - accuracy: 0.8674\n",
            "Epoch 49/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.5590 - accuracy: 0.8684\n",
            "Epoch 50/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.5374 - accuracy: 0.8703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4b100236a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8-hBRzM0O7y"
      },
      "source": [
        "<p>As amusing as it is to train a model and do nothing with it, we should test our acuracy. Keras models have a built in method for this. When we call the evaluate method on a Keras model and give it a set of test data and test labels, it will output a tuple with the loss function and the accuracy function, which we can use to evaluate the effectiveness of the model on unseen data.</p>\n",
        "<p>In the cell below, we add a print statement to help organize the results of the scoring function and print them into a nice readable format.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy09YSNt0O7y",
        "outputId": "7c6225f7-d745-4c4d-c259-047bf2fb39a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "score = model.evaluate(test_x, test_y)\n",
        "print('\\nloss is: ' + str(score[0]))\n",
        "print('accuracy is: ' + str(score[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 1.4866 - accuracy: 0.8732\n",
            "\n",
            "loss is: 1.4866358041763306\n",
            "accuracy is: 0.873199999332428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "ekoBFf6Q0O70"
      },
      "source": [
        "<p>Thats not too bad... But I think we can do better</p>\n",
        "<p>In this example we created a dense network, which doesn't take into account the information we can get from looking at how two pixels next to one another relate. To do that, we use a convolutional neural network.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n8qQV-a0O71"
      },
      "source": [
        "<h1>Building a Convolutional Network</h1>\n",
        "<p>The process for building a convolutional network is VERY similar to building a dense network, except we need to use a different set of layers. Lets start by creating another dense model.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBfi-Mvv0O71"
      },
      "source": [
        "model2 = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmjZFGSR0O75"
      },
      "source": [
        "<p>Now we need to add some layers. We're going to add layers in \"bunches\" with a Convultional Layer, a pooling layer, and a dropout layer, and a normalization layer. In the example below, we've added 3 sets of these layers, but the best way to start is with a single set, and gradually add more sets of layers. Starting with a single set and changing the parameters - primarily the kernel_size and pool_size paramteres - will help you get a sense of how these parameters impact both the accuracy and the speed with which the network trains.</p>\n",
        "<p>To do this, we'll need to import a few different types of layers.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpQ7pUV80O75"
      },
      "source": [
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, BatchNormalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko_7o2bC0O77"
      },
      "source": [
        "# First set of layers\n",
        "model2.add(Conv1D(filters = 236, kernel_size = 2,  input_shape = (28, 28), activation = 'relu'))\n",
        "model2.add(MaxPooling1D(pool_size = 2))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "# Second set of layers\n",
        "model2.add(Conv1D(filters = 128, kernel_size = 2, activation = 'relu'))\n",
        "model2.add(MaxPooling1D(pool_size = 2))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "# Third set of layers\n",
        "model2.add(Conv1D(filters = 64, kernel_size = 2, activation = 'relu') )\n",
        "model2.add(MaxPooling1D(pool_size = 2))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(BatchNormalization())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioPE2jHH0O79"
      },
      "source": [
        "<p>Now we need to flatten the network (since the convlutional later and the pooling layer don't alter the dimensions, we still have a network that has both height and width). To do this we'll use a \"Flatten\" layer, and connect that flatten layer to the output layer.<p> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-2CoAN90O7-"
      },
      "source": [
        "model2.add(Flatten())\n",
        "model2.add(Dense(units = 10, activation = 'softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdSTZ9EX0O7_"
      },
      "source": [
        "<p>With all the layers in place, lets compile the model.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlmVnI240O7_"
      },
      "source": [
        "# Comile the model and set the loss functions, and targets, etc. \n",
        "model2.compile(loss = 'categorical_crossentropy', \n",
        "              optimizer = tensorflow.keras.optimizers.Adadelta(), \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4Iln_SZ0O8B"
      },
      "source": [
        "<p>Now we can fit the model.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "JZBIZvGv0O8C",
        "outputId": "97912bb5-a115-451d-c7f7-369d9ecf93db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "model2.fit(train_x, train_y, epochs = 10, batch_size = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "6000/6000 [==============================] - 24s 4ms/step - loss: 2.8099 - accuracy: 0.1445\n",
            "Epoch 2/10\n",
            "6000/6000 [==============================] - 24s 4ms/step - loss: 2.3982 - accuracy: 0.2321\n",
            "Epoch 3/10\n",
            "6000/6000 [==============================] - 24s 4ms/step - loss: 2.1193 - accuracy: 0.3072\n",
            "Epoch 4/10\n",
            "6000/6000 [==============================] - 24s 4ms/step - loss: 1.8969 - accuracy: 0.3713\n",
            "Epoch 5/10\n",
            "6000/6000 [==============================] - 23s 4ms/step - loss: 1.7271 - accuracy: 0.4250\n",
            "Epoch 6/10\n",
            "6000/6000 [==============================] - 23s 4ms/step - loss: 1.5967 - accuracy: 0.4683\n",
            "Epoch 7/10\n",
            "6000/6000 [==============================] - 23s 4ms/step - loss: 1.4918 - accuracy: 0.5027\n",
            "Epoch 8/10\n",
            "6000/6000 [==============================] - 24s 4ms/step - loss: 1.3974 - accuracy: 0.5362\n",
            "Epoch 9/10\n",
            "6000/6000 [==============================] - 24s 4ms/step - loss: 1.3128 - accuracy: 0.5659\n",
            "Epoch 10/10\n",
            "6000/6000 [==============================] - 23s 4ms/step - loss: 1.2498 - accuracy: 0.5873\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4ab5ef3470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khgGMkKX0O8E"
      },
      "source": [
        "<p>Now lets take a look at how good the model is by evaluating it using the score function.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG1rfrk-0O8F",
        "outputId": "209f34f2-22e4-423b-84b1-2101533c3c9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "score = model2.evaluate(test_x, test_y)\n",
        "print('\\nloss is: ' + str(score[0]))\n",
        "print('accuracy is: ' + str(score[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8203 - accuracy: 0.7738\n",
            "\n",
            "loss is: 0.8203468918800354\n",
            "accuracy is: 0.7738000154495239\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICrS2s9E0O8H"
      },
      "source": [
        "<p>One of the ways we can tune the model is by tuing both the number of units in the hidden layer (called filters) and the number of pixels we look at (called the \"kernel_size\"). Adjusting these up and down will change the results. You can try that now. Remeiber that every time you want to add layers to the model, you have to reinitialize it, by calling model2 = Sequential()</p>\n",
        "<p>You can also add different layers, and maybe even a second set of convolutional layers (a second convolutional layer, a second pooling layer and a second dropout layer) to see whether those give you better results. Adding a second set of layers is REALLY helpful for some of the problems you'll face with other datasets.</p>\n",
        "<p>Finally, you can adjust the time you spend training the network - the number of Epochs and the batch size - to see how that impacts the network and the score. Go ahead and try those and see what impact they have on the results.</p>\n",
        "<p>When you feel comfortable, it's time to move on and pick one of the real datasets to build your own deep learning network!</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iiNfv7H0O8H"
      },
      "source": [
        "## Lets Talk about Some Errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG5xFZWu0O8I"
      },
      "source": [
        "<p>There is a common, but annoying error you may get as you train your network. It's long, and scary and will make you think you've done something terrible... but you haven't done anything wrong. Scroll all the way to the bottom to see what the error actually says (the rest is called a \"Stack Trace\" and shows you everything that happened to trigger the error). Typically it will say something like \"Negative dimension caused by subtracting x from y.\"<p> \n",
        "<p>The foundation is that every time you pass your image through a layer in the neural network, you change the shape of the matrix. Sometimes, if we change the shape in the wrong way, we end up trying to subtract more than we have available. If you think of the matrix as a cube, this would be equivalent to turning the image inside out, which is obviously not ideal.<p>\n",
        "<p>When you get this error, the simple solution is to reduce the size of the arguments that decrease the size of the matrix - these are arguments like \"kernels,\" \"pool_size,\" \"stries,\" etc.. If you want to be a little more precise, you can find out more about the input and output dimensions for each layer by accessing them using the .layers method on your model.<p> \n",
        "<p>Our model is called model2, so we'd do something like this: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOSBV5660O8I",
        "outputId": "870fccab-ce25-4085-e736-a8dcf4ab465c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "# This is a list of all the layers in out model. \n",
        "model2.layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.layers.convolutional.Conv1D at 0x7f4ab4672390>,\n",
              " <tensorflow.python.keras.layers.pooling.MaxPooling1D at 0x7f4ab46727b8>,\n",
              " <tensorflow.python.keras.layers.core.Dropout at 0x7f4ab4672780>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7f4b24dd54a8>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv1D at 0x7f4b26d1b668>,\n",
              " <tensorflow.python.keras.layers.pooling.MaxPooling1D at 0x7f4b27925358>,\n",
              " <tensorflow.python.keras.layers.core.Dropout at 0x7f4b279261d0>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7f4ab5ee47f0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv1D at 0x7f4ab4663eb8>,\n",
              " <tensorflow.python.keras.layers.pooling.MaxPooling1D at 0x7f4b10023048>,\n",
              " <tensorflow.python.keras.layers.core.Dropout at 0x7f4b1009b7b8>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7f4b5817a358>,\n",
              " <tensorflow.python.keras.layers.core.Flatten at 0x7f4ab5ef0128>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7f4ab466dc88>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xob7H5Cq0O8K",
        "outputId": "205dcee6-ce0a-46d2-fbc0-7ce648b00ad5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# Since it's a list, we can access the layers using their index (which starts at 0 with Python)\n",
        "# This is the first layer. \n",
        "print(model2.layers[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.layers.convolutional.Conv1D object at 0x7f4ab4672390>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btJg2EJq0O8N"
      },
      "source": [
        "<p>Now we can use the .output_shape and .input_shape arguments on a single layer to find the size of the layers passing into and out of that layer. This means we can \"see\" the dimensions and the impact the paramters have on the dimensions of the matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEd0jKy20O8O",
        "outputId": "e0b9b4c2-d3ec-496b-bf38-86507e1bcb7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# This gives us the input shape. \n",
        "# Since we're looking at the first layer, this should be the same format as our data. \n",
        "print(model2.layers[0].input_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmD5zTzJ0O8P",
        "outputId": "b14ff9fc-4c79-45ab-a822-baa713c5110d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# By using the .output_shape method, we can see the impact that layer has on the dimensions of our matrix. \n",
        "# Oh look - the final dimension is now the same as our \"kernel_size\" argument. \n",
        "# and we lost 1 from the original rows argument. \n",
        "print(model2.layers[0].output_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 27, 236)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXbYqNdc0O8R"
      },
      "source": [
        "<p>You can do that for ANY layer in your network. This isn't a requirement, but it might help you troublshoot as you're building, tuning and otherwise doing awesome things with your network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQJWlMKI0O8R"
      },
      "source": [
        "The lines of code below generate an error. You'll see there are little arrows ( ----> ) showing the line on which the error occured, and if you scroll all the way to the bottom, you can see a description of the error. In this case, the model was expecting a layer with 2 dimensions, but got a layer with 3 dimensions.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxa6RRZh0O8S",
        "outputId": "4e83f20f-7fb5-4fef-80c1-d929de1363e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "model2.add(Conv1D(filters = 64, kernel_size = 2) )\n",
        "model2.add(MaxPooling1D(pool_size = 2))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(BatchNormalization())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-2a8a6fbd01ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    219\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1090\u001b[0m       \u001b[0;31m# TODO(reedwm): We should assert input compatibility after the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m       \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m       \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Use `self._name_scope()` to avoid auto-incrementing the name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    194\u001b[0m                          \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                          \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                          str(x.shape.as_list()))\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv1d_3 is incompatible with the layer: : expected min_ndim=3, found ndim=2. Full shape received: [None, 10]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXpyc-YR0O8W"
      },
      "source": [
        "The code below generates an error because I step the pool size down too quickly, which means the layers essentially run out of dimensions. Again - in the error message, if you scroll down a little there's an arrow next to the layer that caused the issue, and a description of the error message all the way at the bottom. When you get a negative dimension error, thats probably because you stepped down either the pool size or the kernel size too quickly, and the matrix got too small. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rpqn61wJ0O8W"
      },
      "source": [
        "model2 = Sequential()\n",
        "# First set of layers\n",
        "model2.add(Conv1D(filters = 236, kernel_size = 2,  input_shape = (28, 28)))\n",
        "model2.add(MaxPooling1D(pool_size = 2))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "# Second set of layers\n",
        "model2.add(Conv1D(filters = 128, kernel_size = 2))\n",
        "model2.add(MaxPooling1D(pool_size = 2))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "# Third set of layers\n",
        "model2.add(Conv1D(filters = 64, kernel_size = 2) )\n",
        "model2.add(MaxPooling1D(pool_size = 2))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(BatchNormalization())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkMqt2Aw0O8Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxctJsSg0O8a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYdVYrM40O8c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}